{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a directory to put the data in\n",
    "from pathlib import Path\n",
    "Path(\"./data\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get json file of cards from netrunnerdb\n",
    "f =  open('./data/cards','w')\n",
    "r =  requests.get('https://netrunnerdb.com/api/2.0/public/cards')\n",
    "f.write(r.text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe of cards\n",
    "cards = pd.read_json (r'./data/cards')\n",
    "cards = pd.json_normalize(cards['data'].values)\n",
    "\n",
    "#fix how the cards are numbered to match the decks database \"cards.#####\"\n",
    "cards['code'] = 'cards.'+cards['code']\n",
    "#Remove a card that does not appear in any decks from the dataframe of cards\n",
    "cards = cards[cards['code'] != 'cards.00012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dataframe of corp cards and a dataframe of runner cards\n",
    "corp_cards = cards[cards['side_code']=='corp']\n",
    "runner_cards = cards[cards['side_code']=='runner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a json file of decks from netrunnerdb. We can only request decks by date published\n",
    "#This can take a while (like 30 min)\n",
    "\n",
    "f =  open('./data/decks','w')\n",
    "\n",
    "#make list of dates\n",
    "date1 = '2014-08-27'\n",
    "date2 = '2020-06-07'\n",
    "dates = pd.date_range(date1, date2).strftime('%Y-%m-%d')\n",
    "\n",
    "#we need to make a new json object containing each dates decklists json object\n",
    "f.write('{')\n",
    "\n",
    "#Write out into file \n",
    "for day in dates:\n",
    "    r =  requests.get('https://netrunnerdb.com/api/2.0/public/decklists/by_date/'+day)\n",
    "    f.write('\"'+day+'\": ['+r.text)\n",
    "    f.write('],')\n",
    "\n",
    "#last one hardcoded so there is not comma at the end...\n",
    "lastday='2020-06-08'\n",
    "r =  requests.get('https://netrunnerdb.com/api/2.0/public/decklists/by_date/'+lastday)\n",
    "f.write('\"'+lastday+'\": ['+r.text)\n",
    "f.write(']')\n",
    "\n",
    "#end the json object and close the file\n",
    "f.write('}')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe of decks\n",
    "df =  pd.read_json(r'./data/decks')\n",
    "deck_list = pd.concat([pd.json_normalize(x)['data'] for x in df.values])\n",
    "mask = deck_list.map(lambda d: len(d)) > 0\n",
    "deck_list = deck_list[mask]\n",
    "decks = pd.concat([pd.json_normalize(x) for x in deck_list.values],sort=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the features that we don't care about\n",
    "decks = decks.drop(['date_update','mwl_code','description','name','tournament_badge','user_id','user_name'],axis=1)\n",
    "\n",
    "#fill all the na values for missing cards with 0's\n",
    "decks = decks.fillna(0)\n",
    "\n",
    "#turn all of the deck numbers in np.int8 to reduce file size\n",
    "decks_float = decks.select_dtypes(include=['float'])\n",
    "converted = decks_float.astype(np.int8)\n",
    "decks[converted.columns] = converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of idenity cards\n",
    "identity_cards = cards[cards['type_code'] == 'identity']\n",
    "\n",
    "#make two new features keep track of the idenity cards and the faction\n",
    "for ident in identity_cards['code']:\n",
    "    decks.loc[decks[ident]==1,'identity_card']=ident\n",
    "    decks.loc[decks[ident]==1,'faction']= cards[cards['code']==ident]['faction_code'].values[0]\n",
    "\n",
    "#delete old columns that corresponded to identiy cards\n",
    "decks = decks.drop(identity_cards['code'],axis=1)\n",
    "\n",
    "#remove decks with nan as the faction\n",
    "decks = decks[~decks['faction'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the last few columns types\n",
    "decks['id']=pd.to_numeric(decks['id'], downcast='integer')\n",
    "decks['identity_card'] = decks['identity_card'].astype('string')\n",
    "decks['faction'] = decks['faction'].astype('string')\n",
    "decks['date_creation'] = pd.to_datetime(decks['date_creation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I want to remove decks that are not really decks...the non-identity ones to start off\n",
    "decks = decks[decks['faction'] != 'neutral-runner']\n",
    "decks = decks[decks['faction'] != 'neutral-corp']\n",
    "\n",
    "#now remove the draft format decks\n",
    "draft_cards = ['cards.00005','cards.00006','cards.00007','cards.00008','cards.00009','cards.00010','cards.00011','cards.000013']\n",
    "decks = decks[~decks['identity_card'].isin(draft_cards)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split the decks into corp and runner decks since these are really disjoint data sets\n",
    "corps = ['weyland-consortium','nbn','jinteki','haas-bioroid']\n",
    "runners = ['shaper','criminal','anarch','apex','sunny-lebeau','adam']\n",
    "corp_decks = decks[decks['faction'].isin(corps)]\n",
    "runner_decks = decks[decks['faction'].isin(runners)]\n",
    "\n",
    "#TODO remove all the extra columns and rows from the corp and runner deck\n",
    "#since they only use half the card pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of runner and corp cards in the current deck list\n",
    "mod_runner_cards = runner_cards[runner_cards['code'].isin(decks.keys())]\n",
    "mod_corp_cards = corp_cards[corp_cards['code'].isin(decks.keys())]\n",
    "\n",
    "#then drop the runner and corp card columns\n",
    "corp_decks = corp_decks.drop(list(mod_runner_cards['code']),axis=1)\n",
    "runner_decks = runner_decks.drop(list(mod_corp_cards['code']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle everthing\n",
    "#cards.to_pickle('./data/cards_processed.pkl')\n",
    "corp_cards.to_pickle('./data/corp_cards_processed.pkl')\n",
    "runner_cards.to_pickle('./data/runner_cards_processed.pkl')\n",
    "#decks.to_pickle('./data/decks_processed.pkl')\n",
    "corp_decks.to_pickle('./data/corp_decks_processed.pkl')\n",
    "runner_decks.to_pickle('./data/runner_decks_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
